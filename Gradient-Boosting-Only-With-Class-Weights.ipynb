{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler, PolynomialFeatures\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix, f1_score\nfrom sklearn.model_selection import train_test_split\n\n# Load datasets\nroot = \"/kaggle/input/hackathon-uno-2024-iitmz/\"\ntrain = pd.read_csv(root + 'train.csv')\ntest = pd.read_csv(root + 'test.csv')\n\n# Map the target labels directly\ndisposition_mapping = {'CONFIRMED': 0, 'CANDIDATE': 1, 'FALSE POSITIVE': 2}\ntrain['Disposition'] = train['Disposition'].map(disposition_mapping)\n\n# Drop non-features\nX_train = train.drop(columns=['row_id', 'Disposition'])\ny_train = train['Disposition']\ntest_row_ids = test['row_id']\nX_test = test.drop(columns=['row_id'])\n\n# Handle missing values + scale data\nimputer = SimpleImputer(strategy='mean')\nscaler = StandardScaler()\npoly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n\n# Apply transformations\nX_train = scaler.fit_transform(imputer.fit_transform(X_train))\nX_test = scaler.transform(imputer.transform(X_test))\nX_train = poly.fit_transform(X_train)\nX_test = poly.transform(X_test)\n\n# Train/Test split for validation\nX_train_split, X_val, y_train_split, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n\n# Define the Gradient Boosting model with class weights\ngb = GradientBoostingClassifier(\n    n_estimators=200,          # Number of boosting stages\n    learning_rate=0.1,         # Learning rate\n    max_depth=3,               # Maximum depth of the individual estimators\n    random_state=42,\n    # Manually handling class weights by adjusting sample weights\n    subsample=1.0,\n    max_features='sqrt'\n)\n\n# Compute class weights\nclass_weights = {0: 1, 1: 3.5, 2: 1}\nsample_weights = np.array([class_weights[class_label] for class_label in y_train_split])\n\n# Fit the model\ngb.fit(X_train_split, y_train_split, sample_weight=sample_weights)\n\n# Predict on validation set\ny_val_pred = gb.predict(X_val)\n\n# Evaluate the model performance\nprint(\"Gradient Boosting Performance on Validation Set:\")\nprint(confusion_matrix(y_val, y_val_pred))\nprint(classification_report(y_val, y_val_pred))\ngb_macro_f1 = f1_score(y_val, y_val_pred, average='macro')\nprint(f\"Gradient Boosting Macro F1 Score: {gb_macro_f1:.4f}\")\n\n# Predict on the test data\ntest_predictions = gb.predict(X_test)\n\n# Reverse mapping for submission\nreverse_mapping = {0: 'CONFIRMED', 1: 'CANDIDATE', 2: 'FALSE POSITIVE'}\ntest_data = test.copy()\ntest_data['Disposition'] = test_predictions\ntest_data['Disposition'] = test_data['Disposition'].map(reverse_mapping)\n\n# Create and save the submission file\nsubmission = pd.DataFrame({\n    'row_id': test_row_ids,\n    'Disposition': test_data['Disposition']\n})\nsubmission.to_csv('submission.csv', index=False)\nprint(f\"Submission file saved as: submission.csv\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}